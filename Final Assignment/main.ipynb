{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised Version\n",
    "- Added a simple calculation example for PCA like in the clustering chapter\n",
    "- Added a simple calculation example for NMF like in the clustering chapter\n",
    "- Documentation for how many NMF features we used\n",
    "- Conclusion: Added more detailled explanations for feature importance\n",
    "\n",
    "We added (Revised) for our **newly added explanations and justifications** - so you can find them more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle\n",
    "\n",
    "Group 1\n",
    "\n",
    "Jenewein Matthias - Jenewein Matthias\n",
    "\n",
    "Kalarickal Dominic - Kalarickal Dominic\n",
    "\n",
    "Leander Leirissa - Bitterzoet\n",
    "\n",
    "Timmer Lars - laltir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Loading packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not all libraries are installed, uncomment the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (0.10.2.post1)\n",
      "Requirement already satisfied: pandas in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (3.8.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.12.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.2.2)\n",
      "Requirement already satisfied: streamlit in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (1.30.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (1.11.4)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (0.59.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from librosa->-r requirements.txt (line 1)) (1.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (4.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (7.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=6.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (14.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (13.3.5)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (0.10.2)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (2.1)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (0.18.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (6.3.3)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from streamlit->-r requirements.txt (line 9)) (2.1.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (4.19.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit->-r requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 9)) (4.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from importlib-metadata<8,>=1.4->streamlit->-r requirements.txt (line 9)) (3.17.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 1)) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa->-r requirements.txt (line 1)) (3.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 9)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 9)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 9)) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 9)) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 9)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 9)) (2.15.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 1)) (2.21)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 9)) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 9)) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\a8779\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit->-r requirements.txt (line 9)) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import functions as f\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading labeled data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('Datasets/labels_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m00248.wav</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m00230.wav</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m00637.wav</td>\n",
       "      <td>hiphop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m00627.wav</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m00138.wav</td>\n",
       "      <td>reggae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename    genre\n",
       "0  m00248.wav    metal\n",
       "1  m00230.wav  country\n",
       "2  m00637.wav   hiphop\n",
       "3  m00627.wav    metal\n",
       "4  m00138.wav   reggae"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled files: ['m00002.wav', 'm00039.wav', 'm00041.wav', 'm00072.wav', 'm00096.wav', 'm00102.wav', 'm00112.wav', 'm00138.wav', 'm00192.wav', 'm00206.wav', 'm00230.wav', 'm00236.wav', 'm00248.wav', 'm00253.wav', 'm00298.wav', 'm00313.wav', 'm00338.wav', 'm00339.wav', 'm00351.wav', 'm00400.wav', 'm00421.wav', 'm00429.wav', 'm00435.wav', 'm00454.wav', 'm00477.wav', 'm00501.wav', 'm00503.wav', 'm00513.wav', 'm00553.wav', 'm00606.wav', 'm00623.wav', 'm00627.wav', 'm00629.wav', 'm00633.wav', 'm00637.wav', 'm00658.wav', 'm00671.wav', 'm00676.wav', 'm00677.wav', 'm00678.wav', 'm00716.wav', 'm00762.wav', 'm00772.wav', 'm00773.wav', 'm00801.wav', 'm00821.wav', 'm00850.wav', 'm00867.wav', 'm00895.wav', 'm00996.wav']\n",
      "Unlabeled files: ['m00003.wav', 'm00012.wav', 'm00013.wav', 'm00043.wav', 'm00044.wav', 'm00055.wav', 'm00061.wav', 'm00063.wav', 'm00069.wav', 'm00074.wav', 'm00107.wav', 'm00114.wav', 'm00127.wav', 'm00137.wav', 'm00139.wav', 'm00148.wav', 'm00149.wav', 'm00156.wav', 'm00183.wav', 'm00211.wav', 'm00218.wav', 'm00228.wav', 'm00247.wav', 'm00254.wav', 'm00266.wav', 'm00289.wav', 'm00292.wav', 'm00293.wav', 'm00309.wav', 'm00318.wav', 'm00321.wav', 'm00323.wav', 'm00324.wav', 'm00331.wav', 'm00348.wav', 'm00355.wav', 'm00356.wav', 'm00357.wav', 'm00359.wav', 'm00363.wav', 'm00371.wav', 'm00372.wav', 'm00391.wav', 'm00393.wav', 'm00399.wav', 'm00405.wav', 'm00414.wav', 'm00434.wav', 'm00463.wav', 'm00468.wav', 'm00487.wav', 'm00495.wav', 'm00515.wav', 'm00528.wav', 'm00537.wav', 'm00538.wav', 'm00549.wav', 'm00555.wav', 'm00560.wav', 'm00570.wav', 'm00571.wav', 'm00576.wav', 'm00581.wav', 'm00582.wav', 'm00589.wav', 'm00597.wav', 'm00610.wav', 'm00616.wav', 'm00624.wav', 'm00635.wav', 'm00685.wav', 'm00705.wav', 'm00708.wav', 'm00719.wav', 'm00730.wav', 'm00733.wav', 'm00736.wav', 'm00755.wav', 'm00756.wav', 'm00791.wav', 'm00806.wav', 'm00812.wav', 'm00817.wav', 'm00824.wav', 'm00828.wav', 'm00829.wav', 'm00833.wav', 'm00838.wav', 'm00843.wav', 'm00852.wav', 'm00873.wav', 'm00921.wav', 'm00927.wav', 'm00928.wav', 'm00941.wav', 'm00947.wav', 'm00949.wav', 'm00950.wav', 'm00961.wav', 'm00967.wav', 'm00971.wav', 'm00973.wav', 'm00988.wav', 'm00991.wav', 'm00995.wav']\n"
     ]
    }
   ],
   "source": [
    "labeled_files = os.listdir('Datasets/labeled')\n",
    "unlabeled_files = os.listdir('Datasets/unlabeled')\n",
    "\n",
    "print(\"Labeled files:\", labeled_files)\n",
    "print(\"Unlabeled files:\", unlabeled_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Process Features from Audio Files  \n",
    "This cell handles the loading and processing of features extracted from labeled and unlabeled audio files:  \n",
    "- An instance of the `DataLoader` class is initialized.  \n",
    "- The `featureDataFrame` method is called twice to generate DataFrames containing features for labeled and unlabeled files:  \n",
    "  - Labeled features are extracted from the `labeled_files` directory and saved in `labeled_features_df`.  \n",
    "  - Unlabeled features are extracted from the `unlabeled_files` directory and saved in `unlabeled_features_df`.  \n",
    "- The `labeled_features_df` DataFrame is merged with the `labels` DataFrame on the `filename` column to associate labels with the features.  \n",
    "\n",
    "Finally, both the labeled and unlabeled DataFrames are displayed to preview their structure and contents.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading m00002.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00039.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00041.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00072.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00096.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00102.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00112.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00138.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00192.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00206.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00230.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00236.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00248.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00253.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00298.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00313.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00338.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00339.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00351.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00400.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00421.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00429.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00435.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00454.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00477.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00501.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00503.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00513.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00553.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00606.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00623.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00627.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00629.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00633.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00637.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00658.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00671.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00676.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00677.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00678.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00716.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00762.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00772.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00773.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00801.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00821.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00850.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00867.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00895.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00996.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00003.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00012.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00013.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00043.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00044.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00055.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00061.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00063.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00069.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00074.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00107.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00114.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00127.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00137.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00139.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00148.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00149.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00156.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00183.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00211.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00218.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00228.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00247.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00254.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00266.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00289.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00292.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00293.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00309.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00318.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00321.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00323.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00324.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00331.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00348.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00355.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00356.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00357.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00359.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00363.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00371.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00372.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00391.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00393.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00399.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00405.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00414.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00434.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00463.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00468.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00487.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00495.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00515.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00528.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00537.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00538.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00549.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00555.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00560.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00570.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00571.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00576.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00581.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00582.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00589.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00597.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00610.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00616.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00624.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00635.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00685.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00705.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00708.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00719.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00730.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00733.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00736.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00755.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00756.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00791.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00806.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00812.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00817.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00824.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00828.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00829.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00833.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00838.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00843.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00852.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00873.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00921.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00927.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00928.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00941.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00947.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00949.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00950.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00961.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00967.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00971.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00973.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00988.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00991.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error loading m00995.wav: A process in the process pool was terminated abruptly while the future was running or pending.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10084\\3149093639.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlabeled_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatureDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Datasets/labeled'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0munlabeled_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatureDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munlabeled_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Datasets/unlabeled'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mlabeled_features_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabeled_features_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Labeled Features DataFrame\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_features_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\A8779\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10483\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10484\u001b[0m     ) -> DataFrame:\n\u001b[0;32m  10485\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10487\u001b[1;33m         return merge(\n\u001b[0m\u001b[0;32m  10488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10489\u001b[0m             \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10490\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\A8779\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         )\n\u001b[0;32m    168\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         op = _MergeOperation(\n\u001b[0m\u001b[0;32m    170\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\A8779\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\A8779\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                         \u001b[1;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m                         \u001b[1;31m#  the latter of which will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1287\u001b[1;33m                         \u001b[0mleft_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1288\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m                         \u001b[1;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\A8779\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'filename'"
     ]
    }
   ],
   "source": [
    "dl = f.DataLoader()\n",
    "\n",
    "labeled_features_df = dl.featureDataFrame(labeled_files, 'Datasets/labeled')\n",
    "unlabeled_features_df = dl.featureDataFrame(unlabeled_files, 'Datasets/unlabeled')\n",
    "\n",
    "labeled_features_df = labeled_features_df.merge(labels, on='filename')\n",
    "\n",
    "print(\"Labeled Features DataFrame\")\n",
    "display(labeled_features_df.head())\n",
    "\n",
    "print(\"\\nUnlabeled Features DataFrame\")\n",
    "display(unlabeled_features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Explanations and Calculations in Machine Learning Audio Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract different features from the audio files, we used the `librosa` library. The librosa library offers many different features to explore and is therefore particularly useful for a task like this.\n",
    "\n",
    "For a reference please, have a look at the function.py or more specifically the \"extract_features\" method as well as the librosa documentation (https://librosa.org/doc/latest/index.html). All the methods used were taken from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spectral Centroid\n",
    "\n",
    "**Explanation:**  \n",
    "The spectral centroid represents the center of gravity of the spectral energy distribution. A higher spectral centroid is indicative of a brighter sound. It quantifies the frequency where the majority of the signal's energy resides (Sable, 2021).  \n",
    "\n",
    "**Calculation:**  \n",
    "Using the `librosa` library, the spectral centroid is computed as the weighted mean of the frequencies, with the magnitudes serving as weights (Librosa, n.d.-a).  \n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "\\text{Spectral Centroid}[t] = \\frac{\\sum_{k} S[k, t] \\cdot \\text{freq}[k]}{\\sum_{j} S[j, t]}\n",
    "$$\n",
    "Where:  \n",
    "- \\(s\\): Magnitude spectogram  \n",
    "- \\(freq\\): Array of frequency values. \n",
    "\n",
    "(Librosa, n.d.-a).\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the spectral centroid differs vastly between genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('spectral_centroid', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spectral Bandwidth\n",
    "\n",
    "**Explanation:**  \n",
    "Spectral bandwidth represents the spread (distinction between high and low) frequencies. The bandwidth indicates a how noisy or pure a sound sounds (Jakeli, 2023).  \n",
    "\n",
    "**Calculation:**  \n",
    "The spectral bandwidth is computed as the weighted standard deviation of frequencies (Music Information Retrieval, n.d.)\n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "\\left( \\sum_{k} S[k, t] \\cdot \\left( \\text{freq}[k, t] - \\text{centroid}[t] \\right)^p \\right)^{\\frac{1}{p}}\n",
    "$$ \n",
    "Where:  \n",
    "- \\(x(n)\\): Magnitude of the frequency bin.  \n",
    "- \\(f(n)\\): Frequency value.  \n",
    "\n",
    "Librosa (n.d.-b)\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the spectral bandwith differs vastly between genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('spectral_bandwidth', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Zero Crossing Rate (ZCR)\n",
    "\n",
    "**Explanation:**  \n",
    "Zero Crossing Rate measures the rate at which a signal crosses the zero amplitude line (so the prefix changes from positive to negative or vice versa) (OpenAE, n.d.-a). ZCR is an important indicator to capture the smoothness of an audio file (Bckstrm et al., 2022).  \n",
    "\n",
    "**Calculation:**  \n",
    "The ZCR is computed by summing up the zero crossings in a signal and the normalizing by the amount of consecutive samples (=N) (Bckstrm et al., 2022).\n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "ZCR_k = \\frac 1 N \\sum_{h=kM}^{kM+N} |\\text{sign}(x_h) - \\text{sign}(x_{h-1})|,\n",
    "$$\n",
    "\n",
    "where \\( M \\) is the step between analysis windows and \\( N \\) the analysis window length (Bckstrm et al., 2022).\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the zero crossing rate differs vastly between genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('zero_crossing_rate', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Root Mean Square (RMS)\n",
    "\n",
    "**Explanation:**  \n",
    "Root Mean Square (RMS) quantifies the loudness or energy of an audio signal. Higher RMS values correspond to louder sounds (Miraglia, 2024).  \n",
    "\n",
    "**Calculation:**  \n",
    "The RMS is computed as the square root of the mean of the squared amplitudes. (Wikipedia, 2024-a)  \n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "RMS = \\sqrt{\\frac{1}{N} \\sum_{i}^{N-1} x_i^2}\n",
    "$$\n",
    "\n",
    "(OpenAE, n.d.-b)\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the root mean square differs vastly between genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('rms', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Spectral Rolloff\n",
    "\n",
    "**Explanation:**  \n",
    "Spectral rolloff defines the frequency below which a specified percentage (e.g., 85%) of the total spectral energy is concentrated (OpenAE, n.d.-c). This feature has influence on the frequency of the sound (Librosa, n.d.-c)\n",
    "\n",
    "**Calculation:**  \n",
    "The spectral rolloff is calculated by the n% spectral roll off point which is the exact frequency that marks the specicified percentage (e.g., 85%) below the n% energy of all energy is stored (OpenAE, n.d.-c).\n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "\\sum_{m=0}^{r} X_p[m] \\geq \\frac{n}{100} \\sum_{m=0}^{M-1} X_p[m]\n",
    "$$ \n",
    "\n",
    "(OpenAE, n.d.-c)\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the spectral rolloff differs vastly between genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('spectral_rolloff', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. MFCC Means\n",
    "\n",
    "**Explanation:**  \n",
    "Mel-Frequency Cepstral Coefficients (MFCCs) characterize the tonal and textural qualities of an audio signal (perception of loudness or tempo for example). Nowadays, MFCCs are widely used to characterize sound (Sable, 2021).\n",
    "\n",
    "**Calculation:**  \n",
    "The MFCC is calculated by computing the cepstrum coefficient for each frame (Wikipedia, 2024-b). Computing the mean MFCC provides a summary of these features across an entire audio clip.\n",
    "\n",
    "**Mathematical Formula:**\n",
    "\n",
    "$$\n",
    "c_i = \\sum_{n=1}^{N_f} S_n \\cos \\left( (n - 0.5) \\left( \\frac{i \\pi}{N_f} \\right) \\right), \\quad i = 1, \\dots, L\n",
    "$$\n",
    "\n",
    "(Wikipedia, 2024-b)\n",
    "\n",
    "The mathematical equation of calcuting the arithmetic mean of the MFCC values:\n",
    "\n",
    "$$\n",
    "\\text{MFCC}_i = \\frac{1}{n} \\sum_{n=1}^{N} \\text{MFCC}(i, n)\n",
    "$$  \n",
    "\n",
    "(Wikipedia, 2025-a).\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the MFCC mean differs vastly between genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('mfcc_mean_1', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display not just one mean value, we can use a multi-line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature_multiline(df=labeled_features_df, feature_prefix='mfcc_mean_', num_sub_features=7, x_col='genre', x_label='Genre',y_label='Average MFCC Mean',title='MFCC Means per Genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Chroma Mean\n",
    "\n",
    "**Explanation:**  \n",
    "Chroma features capture the energy distribution across the 12 pitch classes (e.g., C, D, E, etc.) within an octave (Sable, 2022). The Chroma Mean represents the average intensity of these pitch classes over the entire audio clip.  \n",
    "\n",
    "**Calculation:**  \n",
    "To calculate \"such chroma vectors all tones of different octave of the corresponding 12 half tones are mapped into one octave. This means that for example tone A is added to a value, whose sum represents a component of the chroma vector, regardless of its respective octave\" (Englmeier et al., 2023, p.185).\n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "CV(i) = \\sum_{m=0}^{M-1} |X_{CQ}(i + 12m)|\n",
    "$$\n",
    "\n",
    "(Englmeier et al., 2023)\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the chroma mean differs vastly between genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('chroma_mean_1', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display not just one mean value, we can use a multi-line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature_multiline(df=labeled_features_df, feature_prefix='chroma_mean_', num_sub_features=7, x_col='genre', x_label='Genre',y_label='Average Chroma Mean',title='Chroma Means per Genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Tempo\n",
    "\n",
    "**Explanation:**  \n",
    "Tempo represents the speed of an audio signal, typically measured in beats per minute (BPM). It plays a crucial role in genre classification (Wikipedia, 2025-b).\n",
    "\n",
    "**Calculation:**  \n",
    "Librosa determines the BPM by finding a global (for the entire audio file) tempo first. This global tempo is then used to build a cost function and afterwards tries to find the best-fitting beat times. The times should present the tempo from the audio as well as possibly (Elis, 2007). \n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "\\text{Tempo (BPM)} = \\frac{60}{\\text{Average Beat Interval (seconds)}}\n",
    "$$\n",
    "\n",
    "(OmniCalculator, 2024)\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the tempp differs vastly between genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('tempo', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Spectral Contrast\n",
    "\n",
    "**Explanation:**  \n",
    "Spectral Contrast quantifies the amplitude difference between high-energy (peaks/top quartile) and low-energy (valleys/bottom quartile) regions within frequency bands (Sable, 2021). \n",
    "\n",
    "**Calculation:**  \n",
    "The Spectral contrast can be calculated by dividing the peak (point with highest energy) through the valley (point with lowest energy). The 10 x log10(rate) is used to properly convert the quotient into decibels (Yuto, 2024). The mean spectral contrast provides an overall summary of these values across all frames.\n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "\\text{Spectral Contrast} = 10 \\times \\log_{10} \\left( \\frac{\\text{Peak Value}}{\\text{Valley Value}} \\right)\n",
    "$$\n",
    "\n",
    "(Yuto, 2024)\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the spectral contrast mean differs vastly between genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('spectral_contrast', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display not just one mean value, we can use a multi-line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature_multiline(df=labeled_features_df,feature_prefix='contrast_mean_',num_sub_features=7,x_col='genre', x_label='Genre',y_label='Average Spectral Contrast Mean', title='Spectral Contrast Means per Genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Tonnetz Mean\n",
    "\n",
    "**Explanation:**  \n",
    "Tonnetz features represent harmonic relationships between pitches, such as intervals or chords (Wikipedia, 2024-c).   \n",
    "\n",
    "**Calculation:**  \n",
    "Librosa transforms chroma features into the Tonnetz space and maps the interval like major third onto two-dimensional coordinates (Librosa, n.d-d). The Tonnetz Mean summarizes these relationships over time and computes the average value.\n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "\\text{Tonnetz Mean}_i = \\frac{1}{n} \\sum_{n=1}^{N} \\text{Tonnetz}(i, n)\n",
    "$$\n",
    "\n",
    "Unfortunately, we were not able to find a good formula for this feature. Hence, we decided to simple describe how the arithmetic mean of the observed Tonnetz values could be calculated (Wikipedia, 2025-a).\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the tonnetz mean differs vastly between genres. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('tonnetz_mean_1', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display not just one mean value, we can use a multi-line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature_multiline(df=labeled_features_df,feature_prefix='tonnetz_mean_', num_sub_features=6, x_col='genre', x_label='Genre',y_label='Average Tonnetz Mean',title='Tonnetz Means per Genre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Spectral Flatness\n",
    "\n",
    "**Explanation:**  \n",
    "Spectral Flatness measures the resemblance of a sound to a pure tone. Lower values indicate purer tones, while higher values suggest noise-like signals (Wikipedia, 2024-d).  \n",
    "\n",
    "**Calculation:**  \n",
    "The spectral flatness is calculated by dividing the geometric mean by the arithmetic mean of the spectral magnitudes (Wikipedia, 2024-d).\n",
    "\n",
    "**Mathematical Formula:**  \n",
    "$$\n",
    "\\text{Flatness} = \\frac{geometric} {arithmetic} = \\frac{\\sqrt[N]{\\prod_{n=0}^{N-1} x(n)}}{\\frac{\\sum_{n=0}^{N-1} x(n)}{N}} \n",
    "= \\frac{\\exp\\left(\\frac{1}{N} \\sum_{n=0}^{N-1} \\ln x(n)\\right)}{\\frac{1}{N} \\sum_{n=0}^{N-1} x(n)}\n",
    "$$\n",
    "\n",
    "(Wikipedia, 2024-d)\n",
    "\n",
    "**Reason for including this feature:**  \n",
    "The chart below shows that this feature is important to distinguish genres as the spectral flatness differs vastly between genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.visualize_feature('flatness_mean', labeled_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially the genres \"pop\" & \"classical\" often seem to differ a lot from the rest of the genres which makes them potential candidates to be one of the clusters. Of course this is only based now on the labeled dataset and has to be analysed thoroughly.  So we calcualte the average mean for all features per genre and map them agains the average feature value across ALL features and display them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_features_by_genre = labeled_features_df.groupby('genre').mean().reset_index()\n",
    "\n",
    "avg_features_by_genre['overall_mean'] = avg_features_by_genre.drop('genre', axis=1).mean(axis=1)\n",
    "\n",
    "average_mean_across_genres = avg_features_by_genre.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre = labeled_features_df.groupby('genre').mean().reset_index()\n",
    "\n",
    "df_genre['overall_mean'] = df_genre.drop('genre', axis=1).mean(axis=1)\n",
    "\n",
    "average_mean_across_genres = df_genre['overall_mean'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(df_genre['genre'], df_genre['overall_mean'], color='blue', s=100, label='Genre Overall Mean')\n",
    "\n",
    "plt.axhline(y=average_mean_across_genres, color='red', linestyle='--', linewidth=2, label='Average Mean Across Genres')\n",
    "\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Overall Mean')\n",
    "plt.title('Overall Genre Means\\nMapped around the Average Mean Across Genres')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the average values of all features per genre against the total average value across all features and genres, supports our first guess that the genres \"classical\" and \"pop\" are good candidates for potential clusters based on the labeled dataset. A third potential cluster could either be metal or hiphop because they seemingly display a decent average of the values of the other clusters (except classical and pop). \n",
    "\n",
    "Of course, this needs more in-depth analysis for the unlabeled dataset but the EDA of the labeled datasets provides useful insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Numeric Features for NMF Compatibility  \n",
    "This cell processes numeric features from the labeled and unlabeled feature DataFrames to prepare them for Non-Negative Matrix Factorization (NMF):  \n",
    "- Numeric columns are extracted from both `unlabeled_features_df` and `labeled_features_df` using `select_dtypes(include=[np.number])`.  \n",
    "- If a `cluster` column exists, it is dropped from both DataFrames to ensure only relevant features are included.  \n",
    "- A `MinMaxScaler` is initialized with a range of 1 to 2. This scaling range was chosen to avoid issues with non-negative numbers encountered during NMF when using `StandardScaler` or a `MinMaxScaler` with a 0 to 1 range.  \n",
    "- The scaler is fitted on the unlabeled numeric features (`unlabeled_numeric`) and applied to transform both unlabeled and labeled numeric features.  \n",
    "\n",
    "The resulting scaled feature arrays (`unlabeled_scaled` and `labeled_scaled`) are now ready for dimensionality reduction or further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_numeric = unlabeled_features_df.select_dtypes(include=[np.number])\n",
    "labeled_numeric = labeled_features_df.select_dtypes(include=[np.number])\n",
    "\n",
    "if 'cluster' in unlabeled_numeric.columns:\n",
    "    unlabeled_numeric.drop('cluster', axis=1, inplace=True)\n",
    "    \n",
    "if 'cluster' in labeled_numeric.columns:\n",
    "    labeled_numeric.drop('cluster', axis=1, inplace=True)\n",
    "    \n",
    "scaler = MinMaxScaler((1, 2))\n",
    "\n",
    "unlabeled_scaled = scaler.fit_transform(unlabeled_numeric)\n",
    "labeled_scaled = scaler.transform(labeled_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_knn = pd.DataFrame(unlabeled_scaled, columns=unlabeled_numeric.columns)\n",
    "labeled_knn = pd.DataFrame(labeled_scaled, columns=labeled_numeric.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering:\n",
    "\n",
    "K-Means Clustering is an **unsupervised learning algorithm** designed to partition an unlabeled dataset into distinct clusters. The parameter \\( K \\) specifies the number of clusters, e.g., $ K = 5 $ creates **five clusters**, and $ K = 10 $ forms **ten clusters**.  \n",
    "\n",
    "#### Objectives of K-Means Clustering:  \n",
    "1. Identify the optimal positions of $ K $ cluster centers (centroids).  \n",
    "2. Assign each data point to the closest cluster based on **distance metrics**.  \n",
    "\n",
    "\n",
    "### Workflow of the K-Means Algorithm  \n",
    "\n",
    "#### **Step 1: Choose the Number of Clusters ($ K $)**  \n",
    "- Determine $ K $ using methods like the **Elbow Method** or domain knowledge.  \n",
    "\n",
    "#### **Step 2: Initialize $ K $ Cluster Centers**  \n",
    "- Randomly select $ K $ data points as initial cluster centers.  \n",
    "\n",
    "#### **Step 3: Compute Distances**  \n",
    "- Calculate the distance between each data point and all cluster centers using the **Euclidean distance**:  \n",
    "  \n",
    "  $$\n",
    "  D^{(n,k)} = \\sqrt{\\sum_{m=1}^{M} \\left( x_m^{(k)} - c_m^{(k)} \\right)^2 }\n",
    "  $$  \n",
    "\n",
    "#### **Step 4: Assign Data Points to Clusters**  \n",
    "- Allocate each data point to the cluster with the nearest center based on the computed distances.  \n",
    "\n",
    "#### **Step 5: Update Cluster Centers**  \n",
    "- Recalculate the cluster centers as the **mean** of the data points assigned to each cluster:  \n",
    "\n",
    "#### **Step 6: Iterate until good clusters are found**  \n",
    "- Iterate **Steps 3 to 5** until one of the following occurs:  \n",
    "  - Cluster assignments **stabilize**.  \n",
    "  - A **maximum number of iterations** is reached.  \n",
    "  - The cluster centers become **unchanged**.  \n",
    "\n",
    "(Sena, 2024).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering  \n",
    "\n",
    "Hierarchical clustering is an **unsupervised learning algorithm** that groups data points based on similarity. Unlike **K-Means clustering**, hierarchical clustering does not require specifying the number of clusters beforehand. Instead, it generates a **tree-like structure (dendrogram)** that visualizes the hierarchy between data points (Wilson, n.d.-a). \n",
    "\n",
    "\n",
    "\n",
    "### Workflow of Hierarchical Clustering  (using Agglomerative Clustering)\n",
    "\n",
    "1. **Compute Distance of invidual points**  \n",
    "   - Measure the similarity or distance between all pairs of data points.\n",
    "\n",
    "2. **Initialize Each Data Point as a Separate Cluster**  \n",
    "   - Begin with $ n $ clusters, where each cluster contains a single data point.\n",
    "\n",
    "3. **Merge the Closest Clusters**  \n",
    "   - Combine the two clusters that are the most similar.\n",
    "\n",
    "4. **Repeat Until One Cluster Remains**  \n",
    "   - Continue merging clusters iteratively until all points are grouped into a **single cluster** or you cut the clustering at some point.\n",
    "\n",
    "(Patlolla, 2018)\n",
    "\n",
    "### Dendrogram: Visual Representation of Clusters  \n",
    "\n",
    "A **dendrogram** is a hierarchical tree structure that illustrates how clusters are formed.  \n",
    "\n",
    "- A joining of two vertical line displays the merging of two clusters.\n",
    "- The **height of each merge** indicates the distance between merging clusters and hence, the dissimilarity of each cluster.  \n",
    "- A **horizontal cut** at a specific height determines the final number of clusters.  \n",
    "\n",
    "(Wilson, n.d.-a) \n",
    "\n",
    "### Types of Hierarchical Clustering  \n",
    "\n",
    "#### **1. Agglomerative Clustering (Bottom-Up)**  \n",
    "- Begins with **each data point as its own cluster**.  \n",
    "- Clusters are **iteratively merged** based on similarity.  \n",
    "- This is the **most common approach** to hierarchical clustering.  \n",
    "\n",
    "#### **2. Divisive Clustering (Top-Down)**  \n",
    "- Starts with **one large cluster** containing all data points.  \n",
    "- The cluster is **recursively split** into smaller clusters.  \n",
    "- Computationally more intensive and less commonly used.  \n",
    "\n",
    "(Wilson, n.d.-a) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model (GMM)\n",
    "\n",
    "The **Gaussian Mixture Model (GMM)** is a **probabilistic model** used for **unsupervised clustering**. Unlike **K-Means**, which assigns each data point to a single cluster, GMM is a **soft clustering method**, meaning each data point has a **probability of belonging to multiple clusters**.\n",
    "\n",
    "GMM assumes that data is generated from a mixture of multiple **Gaussian distributions**, where each distribution represents a **cluster** in the dataset.\n",
    "\n",
    "(Carrasco, 2019)\n",
    "\n",
    "#### **How GMM Works**\n",
    "\n",
    "A **Gaussian Mixture Model** consists of **$K$ Gaussian distributions**, where each Gaussian is defined by three parameters:\n",
    "\n",
    "1. **Mean ($\\mu$)**  The center of the Gaussian distribution.\n",
    "2. **Covariance ($\\Sigma$)**  Defines the spread and shape of the data.\n",
    "3. **Mixing Coefficient ($\\pi$)**  The probability given by the Gaussian fuction.\n",
    "\n",
    "Each data point is assigned a probability of belonging to a Gaussian component based on the **Gaussian density function**:\n",
    "\n",
    "$$\n",
    "p(x | \\mu, \\Sigma) = \\frac{1}{\\sqrt{(2\\pi)^d |\\Sigma|}} \\exp \\left( -\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $x$ is a data point,\n",
    "- $d$ is the number of dimensions,\n",
    "- $\\mu$ is the mean vector,\n",
    "- $\\Sigma$ is the covariance matrix.\n",
    "\n",
    "(Carrasco, 2019)\n",
    "\n",
    "#### **Expectation-Maximization (EM) Algorithm**\n",
    "\n",
    "The **Expectation-Maximization (EM) algorithm** is an iterative optimization method used to find **maximum-likelihood estimates** for model parameters iteratively until convergence. It is especially useful for missing data or incomplete datasets (GeeksforGeeks, 2024-a).\n",
    "\n",
    "##### **Step 1: Initialization**  \n",
    "- Initialize the **model parameters**:  \n",
    "  - Mean ($\\mu_k$)  \n",
    "  - Covariance matrix ($\\Sigma_k$)  \n",
    "  - Mixing coefficients ($\\pi_k$)\n",
    "\n",
    "(Carrasco, 2019)\n",
    "\n",
    "##### **Step 2: Expectation (E-Step)**\n",
    "- For each data point, calculate the **posterior probabilities**  for every latent variable based on the current parameter estimates.\n",
    "- Estimate missing/incomplete data based on the current parameter estimates.\n",
    "- Compute the log-likelihood based on the current parameter estimates.\n",
    "\n",
    "(GeeksforGeeks, 2024-a)\n",
    "\n",
    "##### **Step 2: Maximization (M-Step)**  \n",
    "- Update the **parameters** initizalized in step 1. In order to achieve this, the log-likelihood from the first step should be maximized.\n",
    "\n",
    "(GeeksforGeeks, 2024-a)\n",
    "\n",
    "##### **Step 3: Iterate Until Convergence**  \n",
    "- Repeat the **E-step and M-step** iteratively until:\n",
    "  - The **log-likelihood function stabilizes**.\n",
    "  - The **parameters do not change**.\n",
    "\n",
    "(GeeksforGeeks, 2024-a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why K-Means is the Best Choice\n",
    "\n",
    "##### **1. Computational Efficiency**\n",
    "- K-Means is significantly **faster** than hierarchical clustering and GMM.  \n",
    "\n",
    "##### **2. Scalability**\n",
    "- Performs **efficiently on large datasets**, making it ideal for clustering **music genres** with **hundreds or thousands** of feature vectors.\n",
    "\n",
    "##### **3. Interpretability & Simplicity**\n",
    "- The **Elbow Method** helps determine the optimal number of clusters.  \n",
    "- Cluster assignments are **clear and deterministic**, ensuring each data point belongs to **only one cluster**.\n",
    "\n",
    "##### **4. Suitable for Music Genre Classification**\n",
    "- While GMM provides **probabilistic assignments**, K-Means is **better suited for distinct genre separation**.  \n",
    "- Most **music features** are naturally **separable**, making **hard clustering** an effective and efficient choice.\n",
    " \n",
    "(Pillai, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short cluster analysis using a Dendogram\n",
    "\n",
    "Although we decided to use KMeans, we still prove the existence of clusters using a Dendogram (Hierarchical Clustering). We use hierachical clustering to quickly show this because in dendograms are useful tools to visualise clusters and determine if there actaully appropriate clusters that can be worked with (Wilson, n.d.-a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [col for col in labeled_features_df.columns if col not in ['filename']]\n",
    "genre_agg = labeled_features_df.groupby('genre')[group_cols].mean().reset_index()\n",
    "\n",
    "display(genre_agg)\n",
    "\n",
    "feature_columns = [col for col in genre_agg.columns if col != 'genre']\n",
    "X = genre_agg[feature_columns].values\n",
    "\n",
    "Z = linkage(X, method='ward')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "labels = labeled_features_df['genre'].values\n",
    "\n",
    "dendrogram(\n",
    "    Z,\n",
    "    labels=genre_agg['genre'].values,\n",
    "    leaf_rotation=90,  \n",
    "    leaf_font_size=10,\n",
    "    color_threshold=0.7 * max(Z[:, 2]) \n",
    ")\n",
    "\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Sample (Genre)')\n",
    "plt.ylabel('Distance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dendogram clearly shows that clusters exist. Based on the structure of the dendogram, there are most likely three clusters in this dataset. \n",
    "\n",
    "1. Cluster: (Classical, Blues, Jazz)\n",
    "2. Cluster: (Pop, Country)\n",
    "3. Cluster (Disco, Hiphop, Reggae, Metal, Rock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 KMeans "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical operations of KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an explanation of KMeans using a small fictious dataset of four datapoints (A,B,C,D) and 2 features (Feature 1 and Feature 2). To calcualte the distances, the Euclidean distance will be used. For simplicity we assume that the number of clusters is 2. \n",
    "\n",
    "| Point | Feature 1 (x) | Feature 2 (x) |\n",
    "|-------|----------------|----------------|\n",
    "| A     | 1.0            | 2.0            |\n",
    "| B     | 2.0            | 3.0            |\n",
    "| C     | 6.0            | 7.0            |\n",
    "| D     | 7.0            | 8.0            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, two random points will be selected to act as the centroids for the clusters. In our case we we will select Point A for cluster 1 and Point D cluster 2. \n",
    "\n",
    "<br>\n",
    "\n",
    "Then, we will calculate the distance from each point to the centroids using the Euclidean distance (theory see above). \n",
    "\n",
    "Point A: The distance towards the first centroid is 0 since its the same point. Point A therefore belongs to cluster 1.\n",
    "\n",
    "Point B: \n",
    "The distance from Point B towards the first centroid can be calculated by: $ \\sqrt{(2 - 1)^2 + (3 - 2)^2} = 1.41 $\n",
    "\n",
    "The distance from Point B towards the second centroid can be calculated by: $ \\sqrt{(2 - 7)^2 + (3 - 8)^2} = 7.07 $\n",
    "\n",
    "**It is quite clear, that Point B belongs to Cluster 1.**\n",
    "\n",
    "Point C:\n",
    "The distance from Point C towards the first centroid can be calculated by: $ \\sqrt{(6 - 1)^2 + (7 - 2)^2} = 7.07 $\n",
    "\n",
    "The distance from Point C towards the second centroid can be calculated by: $ \\sqrt{(7 - 7)^2 + (7 - 8)^2} = 1 $\n",
    "\n",
    "**It is quite clear, that Point C belongs to Cluster 2.**\n",
    "\n",
    "Point D: The distance towards the second centroid is 0 since its the same point. Point D therefore belongs to cluster 2.\n",
    "\n",
    "<br>\n",
    "  \n",
    "After that, the centroids of the newly formed clusters are calculated again (mean of all datapoints):\n",
    "\n",
    "For Cluster 1: Point A + B = $ ((1, 2) + (2, 3))/2 = (1,5/2,5) $\n",
    "\n",
    "For Cluster 2: Point C + D = $ ((6, 7) + (7, 8))/2 = (6,5/7,5) $\n",
    "\n",
    "Based on the newly calculated centroids the calculations from step 1 for all points (A,B,C,D):\n",
    "\n",
    "Point A: \n",
    "The distance from Point A towards the first centroid can be calculated by: $ \\sqrt{(1 - 1,5)^2 + (2 - 2,5)^2} = 0.71 $  \n",
    "\n",
    "The distance from Point A towards the second centroid can be calculated by: $ \\sqrt{(1 - 6,5)^2 + (2 - 7,5)^2} = 7.78 $\n",
    "\n",
    "**It is quite clear, that Point A belongs to Cluster 1.**\n",
    "\n",
    "Point B: \n",
    "The distance from Point B towards the first centroid can be calculated by: $ \\sqrt{(2 - 1,5)^2 + (3 - 2,5)^2} = 0.71 $\n",
    "\n",
    "The distance from Point B towards the second centroid can be calculated by: $ \\sqrt{(2 - 6,5)^2 + (3 - 7,5)^2} = 6.36 $\n",
    "\n",
    "**It is quite clear, that Point B belongs to Cluster 1.**\n",
    "\n",
    "Point C:\n",
    "The distance from Point C towards the first centroid can be calculated by: $ \\sqrt{(6 - 1,5)^2 + (7 - 2,5)^2} = 6.36$\n",
    "\n",
    "The distance from Point C towards the second centroid can be calculated by: $ \\sqrt{(6 - 6,5)^2 + (7 - 7,5)^2} = 0.71 $\n",
    "\n",
    "**It is quite clear, that Point C belongs to Cluster 2.**\n",
    "\n",
    "Point D: \n",
    "The distance from Point D towards the first centroid can be calculated by: $ \\sqrt{(7 - 1,5)^2 + (8 - 2,5)^2} = 7.78 $\n",
    "\n",
    "The distance from Point D towards the second centroid can be calculated by: $ \\sqrt{(7 - 6,5)^2 + (8 - 7,5)^2} = 0.71 $\n",
    "\n",
    "**It is quite clear, that Point D belongs to Cluster 2.**\n",
    "\n",
    "<br>\n",
    "\n",
    "Based on the calculations, KMeans would put Point A and B into the first cluster and Point C and D into the second cluster (Sena, 2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Optimal Number of Clusters for K-Means  \n",
    "This cell uses the `KMeansClustering` class to identify the optimal number of clusters for the unlabeled dataset:  \n",
    "- An instance of the `KMeansClustering` class is initialized with the scaled unlabeled feature data (`unlabeled_scaled`) and the original `unlabeled_features_df`.  \n",
    "- The `finding_k` method is called with a range of cluster numbers (`[2, 11]`).  \n",
    "\n",
    "The range `[2, 11]` was selected based on domain knowledge:  \n",
    "- The labeled dataset contains 10 genres, making it impossible for the unlabeled dataset to contain more than 10 meaningful clusters.  \n",
    "- A minimum of 2 clusters was chosen because having only 1 cluster would indicate no clustering, defeating the purpose of the analysis.  \n",
    "\n",
    "This process helps determine the ideal number of clusters for the dataset using metrics like the elbow method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc = f.KMeansClustering(unlabeled_scaled, unlabeled_features_df)\n",
    "\n",
    "kmc.finding_k([2, 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the Optimal Number of Clusters\n",
    "\n",
    "An iterative approach was applied to determine the optimal number of clusters for the KMeans algorithm. Cluster values ranging from 2 to 10 were evaluated. For each cluster count:\n",
    "\n",
    "- A KMeans model was trained using the scaled features of the \"unlabeled\" dataset.\n",
    "- The **inertia score** (sum of squared distances of samples to their closest cluster center) was recorded to quantify the model's performance.\n",
    "\n",
    "The results were visualized using an **Elbow Method plot** to identify the ideal number of clusters, where the inertia score shows a significant decrease before plateauing (GeeksforGeeks, 2024-b).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Number of Clusters\n",
    "\n",
    "Based on the **Elbow Plot**, the optimal number of clusters was determined to be **three**. This conclusion is drawn from the point where the inertia score shows a significant decrease and begins to plateau, indicating diminishing returns for higher cluster counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = kmc.create_kmeans(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for Clustering and Classification  \n",
    "This cell prepares the data for further analysis and classification:  \n",
    "- The `cluster` column from the clustered DataFrame (`clustered_df`) is added to the `unlabeled_knn` DataFrame.  \n",
    "- The unlabeled dataset is split into features (`unlabeled_X`) and labels (`unlabeled_y`), where the `cluster` column serves as the label.  \n",
    "- The `labeled_knn` DataFrame is assigned to `labeled_X` for use in comparison or model training.  \n",
    "\n",
    "These steps ensure that both labeled and unlabeled datasets are properly structured for clustering and classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_knn['cluster'] = clustered_df['cluster']\n",
    "\n",
    "unlabeled_X, unlabeled_y = unlabeled_knn.drop('cluster', axis=1), unlabeled_knn['cluster']\n",
    "labeled_X = labeled_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Determining genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcv = f.PostClusteringVisualizations(clustered_df, labeled_features_df)\n",
    "\n",
    "pcv.scatter_plot('spectral_centroid', 'spectral_bandwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Analysis: Spectral Bandwidth vs. Spectral Centroid  \n",
    "\n",
    "From the analysis of **spectral bandwidth** and **spectral centroid**, distinct clustering patterns were identified. The mapping of clusters to genres is as follows:  \n",
    "\n",
    "| **Cluster** | **Genres** |  \n",
    "| --- | --- |  \n",
    "| 0 | Pop |  \n",
    "| 1 | Classical |  \n",
    "| 2 | Hip-Hop, Metal, Rock |  \n",
    "\n",
    "This mapping highlights that certain genres, such as **Pop**, form a clearly defined cluster due to unique spectral properties, while others, such as **Hip-Hop**, **Metal**, and **Rock**, share overlapping features, grouping them into a single cluster. These results align with the expectation that genres with similar acoustic characteristics often exhibit overlapping clusters.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcv.scatter_plot('spectral_centroid', 'zero_crossing_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Analysis: Zero Crossing Rate vs. Spectral Centroid  \n",
    "\n",
    "Analyzing the plots of **zero crossing rate** and **spectral centroid** revealed the following genre distributions across clusters:  \n",
    "\n",
    "| **Cluster** | **Genres** |  \n",
    "| --- | --- |  \n",
    "| 0 | Pop |  \n",
    "| 1 | Classical |  \n",
    "| 2 | Hip-Hop, Metal |  \n",
    "\n",
    "#### Key Insights:  \n",
    "- **Cluster 0**: Strongly associated with the **Pop** genre due to its distinct audio features, making it a well-defined cluster.  \n",
    "- **Cluster 1**: Clearly aligned with the **Classical** genre, indicating its unique spectral properties.  \n",
    "- **Cluster 2**: Encompasses genres such as **Hip-Hop** and **Metal**, suggesting overlapping characteristics in terms of zero crossing rate and spectral centroid.  \n",
    "\n",
    "This clustering analysis establishes a clear mapping for genres with distinct audio profiles, while highlighting the need for additional features or techniques to better separate overlapping genres within Cluster 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcv.scatter_plot('spectral_centroid', 'contrast_mean_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Analysis: Contrast Mean 2 vs. Spectral Centroid\n",
    "\n",
    "By analyzing the plots of **Contrast Mean 2** and **Spectral Centroid**, the following genre distributions across clusters were identified:\n",
    "\n",
    "| **Cluster** | **Genres** |\n",
    "| --- | --- |\n",
    "| 0 | Pop |\n",
    "| 1 | Classical | \n",
    "| 2 | Metal |\n",
    "\n",
    "#### Final Genre Assignments\n",
    "From all previous visualizations, we can conclude the following:\n",
    "- **Cluster 0**: Pop\n",
    "- **Cluster 1**: Classical\n",
    "- **Cluster 2**: Metal\n",
    "\n",
    "#### Next Steps\n",
    "To validate these assumptions, a **K-Nearest Neighbors (KNN)** model will be trained to predict the clusters in the labeled dataset. This will help confirm the accuracy of the clustering results and the genre assignments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(unlabeled_X, unlabeled_y)\n",
    "\n",
    "predicted_labels = knn.predict(labeled_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_features_df['cluster'] = predicted_labels\n",
    "\n",
    "clusters_genres = labeled_features_df.groupby(['cluster', 'genre']).size().reset_index().sort_values(by=['cluster', 0], ascending=False)\n",
    "\n",
    "cluster_0 = clusters_genres[clusters_genres['cluster'] == 0]\n",
    "cluster_1 = clusters_genres[clusters_genres['cluster'] == 1]\n",
    "cluster_2 = clusters_genres[clusters_genres['cluster'] == 2]\n",
    "\n",
    "display(cluster_0.head())\n",
    "display(cluster_1.head())\n",
    "display(cluster_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Results: KNN Model\n",
    "\n",
    "After running the KNN model, we can confirm that both the visual analysis and the mathematical operations arrive at the same conclusion regarding genre assignments:\n",
    "\n",
    "| **Cluster** | **Genres** |\n",
    "| --- | --- |\n",
    "| 0 | Pop |\n",
    "| 1 | Classical | \n",
    "| 2 | Metal |\n",
    "\n",
    "This alignment between visual insights and predictive modeling validates the clustering results, confirming the accuracy of the genre assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Mapping clusters to genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0_g = 'pop'\n",
    "c1_g = 'classical'\n",
    "c2_g = 'metal'\n",
    "\n",
    "cluster_genre_mapping = {0: c0_g, 1: c1_g, 2: c2_g}\n",
    "\n",
    "kmc.cluster_to_genre(cluster_genre_mapping)\n",
    "\n",
    "kmc.create_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcar = f.PCAReduction(unlabeled_scaled)\n",
    "\n",
    "pcar.find_n()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis (PCA) Feature Selection  \n",
    "\n",
    "From the PCA plot, it is evident that there is a significant decline in explained variance between the 0th and 1st components, as well as between the 1st and 2nd components. However, beyond the 2nd component, the decline in explained variance becomes negligible.  \n",
    "\n",
    "Based on this observation (using the elbow method), we will select **2 PCA features** for further analysis.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = pcar.reduction(2)\n",
    "pca_features_labeled = pcar.reduce_labeled(labeled_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features_df = pd.DataFrame(pca_features, columns=['PCA 1', 'PCA 2'])\n",
    "pca_features_labeled_df = pd.DataFrame(pca_features_labeled, columns=['PCA 1', 'PCA 2'])\n",
    "pca_features_labeled_df['genre'] = labeled_features_df['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Clustering with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc_pca = f.KMeansClustering(pca_features, unlabeled_features_df)\n",
    "\n",
    "clustered_df_pca = kmc_pca.create_kmeans(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features_df['cluster'] = clustered_df_pca['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcv = f.PostClusteringVisualizations(pca_features_df, pca_features_labeled_df)\n",
    "pcv.scatter_plot('PCA 1', 'PCA 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Results  \n",
    "\n",
    "The PCA reduction has effectively created two features that distinctly separate the three clusters, as observed in the plot. This clear separation indicates that the two principal components are sufficient to capture the underlying structure of the data and distinguish between the clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Determining genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(clustered_df_pca['cluster'], clustered_df['cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Consistency  \n",
    "\n",
    "From the crosstab, we can observe that the clusters are identical, with no differences between them. Therefore, we will apply the same cluster-to-genre mapping as we did for the standard KMeans clustering approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc_pca.cluster_to_genre(cluster_genre_mapping)\n",
    "\n",
    "kmc_pca.create_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Theory PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (principal component analysis) is a way of dimension reduction. This means that using PCA you can analyse the dimension of the datset and reduce these to make a dataset which is smaller, which would improve runtime and makes models less complicated. A downside of PCA is that the resulting dataset is hard to interpret (Jaadi, 2024).\n",
    "\n",
    "PCA divided over 5 steps:\n",
    "1. Scaling the dataset: before any analysis can be run on a dataset it must be scaled.\n",
    "2. Calculate the covariance matrix: since the PCA reduction uses variance to determine which components need to be kept it is important to calculate to covariance \n",
    "3. Calculate the eigenvectors and eigenvalues of the covariancematrix: the values for the newly computed components are the eigenvalues. Therefore it is important to calculate these.\n",
    "4. Sort the eigenvectors from high to low and than sort the eigenvalues in the same order.\n",
    "5. Filter to the amount of components chosen.\n",
    "- (Jaadi, 2024)\n",
    "\n",
    "When would you use PCA?\n",
    "1. When working with linear data: other techniques like t-SNE and UMAP are best suited for non-linear data.\n",
    "2. Computaion: PCA is very computationally efficient.\n",
    "3. Information preservation: PCA preserves the maximum amount of variance in the dataset, which means that information is preserved most efficiently.\n",
    "- (Ibm, 2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revised - Documentation for how many NMF features we used\n",
    "\n",
    "errors = []\n",
    "components_range = range(2, 11)\n",
    "\n",
    "for n in components_range:\n",
    "    nmf_test = NMF(n_components=n, init='random', random_state=42)\n",
    "    nmf_test.fit(unlabeled_scaled)\n",
    "    errors.append(nmf_test.reconstruction_err_)\n",
    "\n",
    "plt.plot(components_range, errors, marker='o')\n",
    "plt.title(\"NMF Reconstruction Error by Number of Components\")\n",
    "plt.xlabel(\"Number of Components (n_components)\")\n",
    "plt.ylabel(\"Reconstruction Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revised - Documentation for how many NMF features we used\n",
    "Based on the reconstruction error, we used 3 NMF components in our functions.py #NMFReduction (O'Donnell, 2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfr = f.NMFReduction(unlabeled_scaled)\n",
    "df_nmf_unlabeled = nmfr.reduction()\n",
    "df_nmf_labeled = nmfr.reduce_labeled(labeled_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmf_labeled['genre'] = labeled_features_df['genre']\n",
    "\n",
    "display(df_nmf_unlabeled.head())\n",
    "display(df_nmf_labeled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Clustering with NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc_nmf = f.KMeansClustering(df_nmf_unlabeled, unlabeled_features_df)\n",
    "\n",
    "clustered_df_nmf = kmc_nmf.create_kmeans(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nmf_unlabeled['cluster'] = clustered_df_nmf['cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcv = f.PostClusteringVisualizations(df_nmf_unlabeled, df_nmf_labeled)\n",
    "pcv.scatter_plot(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Determining genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_nmf_unlabeled['cluster'], clustered_df['cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Consistency  \n",
    "\n",
    "From the crosstab, we can observe that the clusters are identical, with no differences between them. Therefore, we will apply the same cluster-to-genre mapping as we did for the standard KMeans clustering approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc_pca.cluster_to_genre(cluster_genre_mapping)\n",
    "\n",
    "kmc_pca.create_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Theory NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF (non-negative matric factorization) is a method of factorizing a non-negative matrix. It is an unsupervised learning algorithm which reduces dimensionality. It is used for recommendation systems, text mining, and image analysis applications (Eunus, 2025). Unlike PCA NMF models are interpretable and therefore easier to explain (Wilson, n.d.-a). \n",
    "\n",
    "The basic idea of NMF is to split the original dataset (the original matrix) into 2 smaller datasets (2 smaller sub-matrices) that are easier to understand. In order to do that all values must be positive (as the name \"NMF\" already suggests). One of the two sub-matrices are the NMF components and the other matrix represents the NMF features. These 2 matrices can be used to approximately reconstruct the original sample (product matrix of the 2 sub-matrices) (Wilson, n.d.-b).\n",
    "\n",
    "For text documents, the NMF components represent topics (the topic \"music genres\" might cover words like Metal, Pop, Tempo) in the text while NMF features represent how much a text document is influenced by certain topics (an article about music might be heavily influenced by the topic music but there might be other topics like health or climate inside that document - just with a smaller representation.) (Wilson, n.d.-c).\n",
    "\n",
    "To apply these principles to our project, this would mean that the raw features we extracted are used to build components based on patterns the algorithm finds in the dataset (=NMF components that combine a set of raw features like spectral centroid, zero crossing rate or mfcc values - the component \"Metal\" might represent a certain combination of the raw features). The NMF features then try to describe each audio file as a representation of a combination of different components (one audio file might be 90% described by Component 1 (=Metal) and 10% by Component 2 (=Pop)). Then based on our trained KMeans-model the prediction would happen. In this case, the prediction for the concrete audio file would most likely be Metal. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Important Features for Clustering\n",
    "Our analysis demonstrates that all 11 features play a crucial role in achieving high clustering accuracy. While some features contribute more to specific aspects of genre differentiation, removing any single feature leads to a loss of valuable information and a decline in clustering performance.\n",
    "\n",
    "### 2. Effect and Usefulness of Dimensionality Reduction\n",
    "We applied two dimensionality reduction techniques:\n",
    "\n",
    "- **Principal Component Analysis (PCA)**: Reduced the feature space while retaining the most variance in data. The results showed that PCA helped in visualizing genre clusters effectively and improved classification performance by reducing noise.\n",
    "- **Non-negative Matrix Factorization (NMF)**: Provided a parts-based representation of data, which was particularly useful for uncovering underlying patterns in frequency distributions.\n",
    "\n",
    "### 3. Additional Data for Better Recommendations\n",
    "To enhance the clustering and recommendation system, we identified additional data that could improve results:\n",
    "\n",
    "- **Lyrics Analysis**: Lyrics-based features could enhance genre classification by providing contextual meaning to songs.\n",
    "- **Instrumentation Tags**: Identifying dominant instruments in each song (e.g., guitar for rock, synthesizers for electronic) could refine clustering.\n",
    "- **User Listening History**: Incorporating listener preferences and interaction data would make recommendations more personalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Sources\n",
    "\n",
    "- Bckstrm, T., Rsnen, O., Zewoudie, A., Prez Zarazaga, P., Koivusalo, L., Das, S., Gmez Mellado, E., Bouafif Mansali, M., Ramos, D., Kadiri, S., Alku, P., & Vali, M. H. (2022). *Introduction to Speech Processing* (2nd ed.). Retrieved January 7th, 2025 from https://speechprocessingbook.aalto.fi (doi: https://doi.org/10.5281/zenodo.6821775)\n",
    "\n",
    "- Carrasco, O. C. (2019, June 3). Gaussian Mixture Models Explained. Towards Data Science. Retrieved 20th, 2025 from . https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95\n",
    "\n",
    "- Ellis, D. P. W. (2007, July 16). Beat tracking by dynamic programming. LabROSA, Columbia University. Retrieved January 14th, 2025 from https://www.ee.columbia.edu/~dpwe/pubs/Ellis07-beattrack.pdf\n",
    "\n",
    "- Englmeier, D., Hubig, N., Goebl, S., & Bohm, C. (2015). Musical similarity analysis based on chroma features and text retrieval methods. University of Munich; Helmholtz Center Munich. Retrieved January 28th, 2025 from https://www.medien.ifi.lmu.de/pubdb/publications/pub/englmeier2015btw/englmeier2015btw.pdf\n",
    "\n",
    "- GeeksforGeeks. (2024, August 28-a). ML | Expectation-Maximization Algorithm. GeeksforGeeks. Retrieved January 20th, 2025, from https://www.geeksforgeeks.org/ml-expectation-maximization-algorithm/\n",
    "\n",
    "- GeeksforGeeks. (2024, November 2-b). Elbow-Methode fr den optimalen k-Wert in KMeans. GeeksforGeeks. Retrieved January 10th, 2025, from https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/\n",
    "\n",
    "- Harpale, V. K., & Bairagi, V. K. (2021). Seizure detection methods and analysis. In *Elsevier eBooks* (pp. 51100). https://doi.org/10.1016/b978-0-32-391120-7.00008-6\n",
    "\n",
    "- Ibm. (2024, December 19). PCA. Think. https://www.ibm.com/think/topics/principal-component-analysis\n",
    "\n",
    "- Jaadi, Z. (2024, February 23). Principal Component Analysis (PCA): A Step-by-Step Explanation. Built In. https://builtin.com/data-science/step-step-explanation-principal-component-analysis\n",
    "\n",
    "- Jakeli, N. (2023, April 25). Clustering audio features. The MCT Blog. Retrieved January 28th, 2025 from https://mct-master.github.io/blog/\n",
    "\n",
    "- Librosa (n.d.-a). Spectral Centroid. Librosa. Retrieved January 3rd, 2025 from https://librosa.org/doc/main/generated/librosa.feature.spectral_centroid.html\n",
    "\n",
    "- Librosa (n.d.-b). Spectral Bandwidth. Librosa. Retrieved January 3rd, 2025 from https://librosa.org/doc/main/generated/librosa.feature.spectral_bandwidth.html\n",
    "\n",
    "- Librosa (n.d.-c). Spectral Rolloff. Librosa. Retrieved January 6th, 2025 from https://librosa.org/doc/main/generated/librosa.feature.spectral_rolloff.html\n",
    "\n",
    "- Miraglia, D. (2024, January 18-a). What is RMS in audio? The absolute BEST beginners guide. Unison Audio. Retrieved January 7th, 2025 from https://unison.audio/what-is-rms-in-audio/\n",
    "\n",
    "- O'Donnell, R. (2024, May 3). Dimensionality reduction: Part 3 non-negative matrix factorisation (NMF). Medium. Retrieved March 1st, 2025 from https://medium.com/@ronanodonnell43/dimensionality-reduction-part-3-non-negative-matrix-factorisation-nmf-0b716caeeb14\n",
    "\n",
    "- OpenAE (n.d.-a). Zero-crossing rate. OpenAE. Retrieved January 6th, 2025 from https://openae.io/features/latest/zero-crossing-rate/\n",
    "\n",
    "- OpenAE (n.d.-b). RMS. OpenAE. Retrieved January 6th, 2025 from https://openae.io/features/latest/rms/\n",
    "\n",
    "- OpenAE (n.d.-c). Spectral Rolloff. OpenAE. Retrieved January 6th, 2025 from https://openae.io/features/latest/spectral-rolloff/\n",
    "\n",
    "- OmniCalculator. (2024, July 28). OmniCalculator. Retrieved January 7th, 2025 from https://www.omnicalculator.com/other/bpm\n",
    "\n",
    "- Patlolla, C. R. (2018, December 10). Understanding the concept of hierarchical clustering technique. Towards Data Science. Retrieved January 17th, 2025 from https://towardsdatascience.com\n",
    "\n",
    "- Pillai, G. (2024, March 3). Music Genre Classification. International Research Journal of Modernization in Engineering Technology and Science, 6(3), 40704076, Retrieved January 5th, 2025 from https://doi.org/10.56726/IRJMETS51043\n",
    "\n",
    "- Sena, M. (2024, May 22). Mastering K-means clustering: Implement the K-Means algorithm from scratch with this step-by-step Python tutorial. Towards Data Science. Retrieved January 25th, 2025, from https://towardsdatascience.com/mastering-k-means-clustering-065bc42637e4\n",
    "\n",
    "- So, N. L., Edwards, J. A., & Woolley, S. M. (2019). Auditory selectivity for spectral contrast in cortical neurons and behavior. *Journal of Neuroscience, 40*(5), 10151027. https://doi.org/10.1523/jneurosci.1200-19.2019\n",
    "\n",
    "- Spectral features. (n.d.). Music Information Retrieval. Retrieved January 28th, 2025 from https://musicinformationretrieval.com/spectral_features.html\n",
    "\n",
    "- Sable, A. (2021). Introduction to audio analysis and synthesis. Paperspace Blog. Retrieved January 6th, 2025, from https://blog.paperspace.com/introduction-to-audio-analysis-and-synthesis/\n",
    "\n",
    "- Sable, A. (2022). An Introduction to Audio Analysis and Processing: Music Analysis. Paperspace Blog. Retrieved January 6th, 2025, from https://blog.paperspace.com/audio-analysis-processing-maching-learning/\n",
    "\n",
    "- Wikipedia. (2024, December 15-a). RMS. Retrieved January 10th, 2025 from https://en.wikipedia.org/wiki/Root_mean_square\n",
    "\n",
    "- Wikipedia. (2024, November 10-b). Mel-frequency cepstrum. Wikipedia. Retrieved January 28th, 2025 from https://en.wikipedia.org/wiki/Mel-frequency_cepstrum\n",
    "\n",
    "- Wikipedia. (2024, November 2-c). Tonnetz. Wikipedia. Retrieved January 5th, 2025 from https://en.wikipedia.org/wiki/Tonnetz\n",
    "\n",
    "- Wikipedia. (2024, November 14-d). Spectral Flatness. Wikipedia. Retrieved January 5th, 2025 from https://en.wikipedia.org/wiki/Spectral_flatness\n",
    "\n",
    "- Wikipedia. (2025, January 8-a). Arithmetic mean. Wikipedia. Retrieved January 28th, 2025 from https://en.wikipedia.org/wiki/Arithmetic_mean\n",
    "\n",
    "- Wikipedia. (2025, January 5-b). Tempo. Wikipedia. Retrieved January 5th, 2025, from https://en.wikipedia.org/wiki/Tempo\n",
    "\n",
    "- Wilson, B. (n.d.-a). Visualization with hierarchical clustering and t-SNE. DataCamp. Retrieved January 20th, 2025, from https://campus.datacamp.com/courses/unsupervised-learning-in-python/visualization-with-hierarchical-clustering-and-t-sne?ex=1\n",
    "\n",
    "- Wilson, B. (n.d.-b). Non-negative matrix factorization. DataCamp. Retrieved January 30th, 2025, from https://campus.datacamp.com/courses/unsupervised-learning-in-python/discovering-interpretable-features?ex=1\n",
    "\n",
    "- Wilson, B. (n.d.-c). NMF learns interpretable parts. DataCamp. Retrieved January 30th, 2025, from https://campus.datacamp.com/courses/unsupervised-learning-in-python/discovering-interpretable-features?ex=6\n",
    "\n",
    "- Yuto. (2024, April 21). Musical similarity analysis based on chroma features and text retrieval methods. Zenn. Retrieved January 14th, 2025 from https://zenn.dev/yuto_mo/articles/7413ca2ed4eb5f\n",
    "\n",
    "- ZalaRushirajsinh. (2023, November 4). The elbow method: finding the optimal number of clusters. Medium. Retrieved January 16th, 2025, https://medium.com/@zalarushirajsinh07/the-elbow-method-finding-the-optimal-number-of-clusters-d297f5aeb189\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
